<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8" />

    

    
    <title>Tensorflow学习（二） | 理想国</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="keywords" content="Tensorflow" />
    
    <meta name="description" content="&amp;emsp;&amp;emsp;当我们学习一个新的编程语言时，输出的第一句话一定是“Hallo World”；当我们学习一个新的深度学习框架时，跑的第一个数据集一定是MNIST。这是Tensorflow官方教程的原话。MNIST是一个简单的计算机图像数据集，它由一系列大小为28×28的手写数字图像以及它们的标记组成（如下图所示），可以算是最简单的数据集之一啦。&amp;emsp;&amp;emsp;本次学习会使用两种不同">
<meta property="og:type" content="article">
<meta property="og:title" content="Tensorflow学习（二）">
<meta property="og:url" content="https://haosutopia.github.io/2018/01/Tensorflow-02/">
<meta property="og:site_name" content="理想国">
<meta property="og:description" content="&amp;emsp;&amp;emsp;当我们学习一个新的编程语言时，输出的第一句话一定是“Hallo World”；当我们学习一个新的深度学习框架时，跑的第一个数据集一定是MNIST。这是Tensorflow官方教程的原话。MNIST是一个简单的计算机图像数据集，它由一系列大小为28×28的手写数字图像以及它们的标记组成（如下图所示），可以算是最简单的数据集之一啦。&amp;emsp;&amp;emsp;本次学习会使用两种不同">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://haosutopia.github.io/images/Tensorflow.png">
<meta property="article:published_time" content="2018-01-12T01:46:15.000Z">
<meta property="article:modified_time" content="2018-01-23T23:10:14.000Z">
<meta property="article:author" content="进击的学渣">
<meta property="article:tag" content="Tensorflow">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://haosutopia.github.io/images/Tensorflow.png">
    

    
        <link rel="alternate" href="/" title="理想国" type="application/atom+xml" />
    

    
        <link rel="icon" href="/css/images/favicon.png" />
    

    
<link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">

    
<link rel="stylesheet" href="/libs/titillium-web/styles.css">

    
<link rel="stylesheet" href="/libs/source-code-pro/styles.css">


    
<link rel="stylesheet" href="/css/style.css">


    
<script src="/libs/jquery/3.5.0/jquery.min.js"></script>

    
    
        
<link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">

    
    
        
<link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">

    
    
        <script type="text/javascript">
(function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-115921256-1', 'auto');
ga('send', 'pageview');

</script>

    
    
        <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?fc799e8461d37896f29cc1ea74f75070";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    
    


<meta name="generator" content="Hexo 5.2.0"></head>

<body>
    <div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                    <h1 class="logo-wrap">
                        <a href="/" class="logo"></a>
                    </h1>
                    
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/home/">主页</a>
                                </li>
                            
                                    <ul class="main-nav-list"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/">控制理论</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%8F%82%E6%95%B0%E7%B3%BB%E7%BB%9F%E6%8E%A7%E5%88%B6/">分布参数系统控制</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%8E%A7%E5%88%B6/">非线性控制</a></li></ul></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li></ul></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a></li></ul>
                                
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/about/">关于</a>
                                </li>
                            
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="想要查找什么..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>


</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>

        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    <a class="page-title-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><i class="icon fa fa-angle-right"></i><a class="page-title-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
    </h1>
</div>

                        <div class="main-body-content">
                            <article id="post-Tensorflow-02" class="article article-single article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        Tensorflow学习（二）
        </h1>
    

            </header>
        
        
            <div class="article-meta">
                
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2018/01/Tensorflow-02/" class="article-date">
       <time datetime="2018-01-12T01:46:15.000Z" itemprop="datePublished">2018-01-12</time>
    </a>
  </div>


<div class="article-date">
  <i class="fa fa-calendar-plus-o"></i>
  <a href="/2018/01/Tensorflow-02/" class="article-date">
     <time datetime="2018-01-23T23:10:14.000Z" itemprop="dateModified">2018-01-24</time>
  </a>
</div>


                

                
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link-link" href="/tags/Tensorflow/" rel="tag">Tensorflow</a>
    </div>

                

                

            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            

            

            

            <p>&emsp;&emsp;当我们学习一个新的编程语言时，输出的第一句话一定是“Hallo World”；当我们学习一个新的深度学习框架时，跑的第一个数据集一定是MNIST。这是Tensorflow官方教程的原话。MNIST是一个简单的计算机图像数据集，它由一系列大小为28×28的手写数字图像以及它们的标记组成（如下图所示），可以算是最简单的数据集之一啦。<br><img src="/images/MNIST.png" alt="MNIST数据集"><br>&emsp;&emsp;本次学习会使用两种不同的方法对MNIST进行训练：Softmax回归和卷积神经网络。它们分别会得到不同精确度的手写数字预测模型。</p>
<h3 id="导入MNIST数据"><a href="#导入MNIST数据" class="headerlink" title="导入MNIST数据"></a>导入MNIST数据</h3><p>&emsp;&emsp;MNIST数据集可以直接在它的<a target="_blank" rel="noopener" href="http://yann.lecun.com/exdb/mnist/">官网</a>上下载，也可以通过Tensorflow的教程文件直接导入。教程文件是我们在安装Tensorflow时自动添加的。这里我们直接将数据从中导入。python中的实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">&quot;MNIST_data/&quot;</span>, one_hot = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;这个代码在运行时会在当前目录下生成一个名为“MNIST_data”的文件夹，并在此文件夹中导入MNIST数据。一共得到四个文件，分别是训练数据、训练标签、测试数据以及测试标签。在接下来的代码中它们可以分别通过mnist.train.images、minst.train.labels、mnist.test.images、mnist.test.labels来调用，非常方便。<br>&emsp;&emsp;函数中的one-hot是针对数据标签的操作。它可以将表示分类的标签y转换为一个只有第y项为1，其余项都为0，且项数为总分类数的向量。这样操作之后，向量的每一项代表了一个分类，当数据属于一个分类时，该分类所属项为1，其余项为0。以此可以更加方便地计算代价函数。举个例子：MNIST数据集一共有10个分类（数字0~9），那么数字3的标签就会转换为[0,0,0,1,0,0,0,0,0,0]。</p>
<h3 id="softmax回归"><a href="#softmax回归" class="headerlink" title="softmax回归"></a>softmax回归</h3><p>&emsp;&emsp;softmax回归比较简单。它相当于在线性模型后增加了一个softmax函数，将线性模型的输出转换到[0,1]区间中，并且使各个类别的输出值相加为1，因此它可以被当成是某个分类的概率。softmax回归模型最终输出为一个向量，其项数为总分类数，并且每项代表一个分类的概率。这与one-hot输出的形式是一样的。</p>
<h4 id="定义张量"><a href="#定义张量" class="headerlink" title="定义张量"></a>定义张量</h4><p>&emsp;&emsp;MNIST的数据x与标签y_为模型的输入，因此使用placeholder类别；而模型参数W与b需要通过数据集训练得到，因此使用Variable类别。定义它们并将其初始化为0。实现代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义张量</span></span><br><span class="line">x = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">784</span>])</span><br><span class="line">y_ = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">10</span>])</span><br><span class="line">W = tf.Variable(tf.zeros([<span class="number">784</span>, <span class="number">10</span>]))</span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br></pre></td></tr></table></figure>
<h4 id="构建computational-graph"><a href="#构建computational-graph" class="headerlink" title="构建computational graph"></a>构建computational graph</h4><p>&emsp;&emsp;softmax回归模型由一个线性模型及softmax函数组成，其输出表达式为：<br>$$y=softmax(W*x+b)$$<br>&emsp;&emsp;其中W与b相乘为矩阵相乘。在Tensorflow中矩阵相乘不能使用普通的乘号，也不能用numpy的函数，必须使用Tensorflow内置的矩阵乘法函数：tf.matmul(mat1, mat2)。softmax函数可以直接使用Tensorflow函数tf.nn.softmax()实现。tf.nn模块包含了几乎所有神经网络要用到的函数，因此之后会经常用到它（<a target="_blank" rel="noopener" href="https://www.tensorflow.org/versions/master/api_docs/python/tf/nn">官方文档</a>）。输出y的实现代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#构建computational graph</span></span><br><span class="line">y = tf.nn.softmax(tf.matmul(x, W) + b)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;我们选择交叉熵函数（cross-entropy）作为代价函数，它是在信息学中最先被提出的。其定义为：<br>$$H_{y’}(y)=-\sum_{i} {y’_ilog(y_i)}$$<br>&emsp;&emsp;求出每个样本的交叉熵后，再对它们求平均值，便得到了损失值。将其表示为代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#代价函数</span></span><br><span class="line">cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices = [<span class="number">1</span>]))</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;其中tf.reduce_sum(input_tensor, axis, reduction_indices)为Tensorflow的求和函数（<a target="_blank" rel="noopener" href="https://www.tensorflow.org/versions/master/api_docs/python/tf/reduce_sum">官方文档</a>），reduction_indices = [1]代表将输入的第二个维度相加，与axis作用一致。tf.reduce_mean(input_tensor, axis)为Tensorflow的均值函数（<a target="_blank" rel="noopener" href="https://www.tensorflow.org/versions/master/api_docs/python/tf/reduce_mean">官方文档</a>）。<br>&emsp;&emsp;而实际上Tensorflow在tf.nn中已经提供了直接求交叉熵代价函数的方程，由于该函数包含了softmax步骤，因此可以将之前的代码改为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#构建computational graph</span></span><br><span class="line">y = tf.matmul(x, W) + b</span><br><span class="line"><span class="comment">#代价函数</span></span><br><span class="line">cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y, labels = y_))</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;其中logits为模型输出值，labels为实际标签值。</p>
<h4 id="训练参数"><a href="#训练参数" class="headerlink" title="训练参数"></a>训练参数</h4><p>&emsp;&emsp;设置训练目标，这里选用梯度下降法，学习率为0.5，训练目标为降低损失值cross_entropy：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#设置训练目标</span></span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.5</span>).minimize(cross_entropy)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;设置Session，初始化Variable，之后使用分批训练的方式，每100个数据为一个batch，通过for循环运行1000次，得到预测模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#设置Session</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line"><span class="comment">#Variable初始化</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess.run(init)</span><br><span class="line"><span class="comment">#分批训练</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    batch_xs, batch_ys = mnist.train.next_batch(<span class="number">100</span>) <span class="comment">#mnist.train.next_batch()函数得到下一batch的数据</span></span><br><span class="line">    sess.run(train_step, feed_dict = &#123;x: batch_xs, y_: batch_ys&#125;) <span class="comment">#使用该批次训练</span></span><br></pre></td></tr></table></figure>
<h4 id="评估模型"><a href="#评估模型" class="headerlink" title="评估模型"></a>评估模型</h4><p>&emsp;&emsp;训练完模型后就可以使用测试数据集来测试模型的精确度了。首先定义精确度，它等于识别正确的数量除以测试总数。精确度可以采用以下代码实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#评估模型</span></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y, <span class="number">1</span>), tf.argmax(y_, <span class="number">1</span>)) <span class="comment">#判断是否识别正确</span></span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) <span class="comment">#计算精确度</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;其中tf.argmax(input, axis)函数（<a target="_blank" rel="noopener" href="https://www.tensorflow.org/versions/master/api_docs/python/tf/argmax">官方文档</a>）为返回一个向量最大值的坐标，第二个参数1表示在向量第二维寻找最大值并返回其坐标（correct_prediction[n][10]第一维n为样本数量，第二维为每个样本的输出）。使用tf.argmax()分别得到模型测试的类别以及真实标签的类别。再使用tf.equal(x, y)函数（<a target="_blank" rel="noopener" href="https://www.tensorflow.org/versions/master/api_docs/python/tf/equal">官方文档</a>）比较它们，得到一系列布尔值的矩阵。它代表预测的分类与实际的分类相同与否，并以此来判断识别是否正确。<br>&emsp;&emsp;tf.cast(x, dtype)函数（<a target="_blank" rel="noopener" href="https://www.tensorflow.org/versions/master/api_docs/python/tf/cast">官方文档</a>）在这里的作用是将布尔值转换为浮点数。最后用均值函数求取均值就得到了模型的测试精确度。<br>&emsp;&emsp;通过Session运行并输出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#输出</span></span><br><span class="line">print(<span class="string">&quot;accuracy:&quot;</span>, sess.run(accuracy, feed_dict = &#123;x: mnist.test.images, y_:mnist.test.labels&#125;))</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;最终得到模型的精确度为：0.9212</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">accuracy: <span class="number">0.9212</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;0.92的精确度显然不能令我们满意，毕竟这只是一个十个数字符号的识别任务。softmax回归模型过于简单，没有考虑图像像素的位置关系。接下来我们将使用一个简单的卷积神经网络来大幅提升精确度。</p>
<h3 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h3><p>&emsp;&emsp;卷积神经网络（Convolutional Neural Network: CNN）常被用于图像的识别，它考虑了输入数据的二维或三维（可能更高）结构，因此对于数字字符图像这样的识别对象非常有效。</p>
<h4 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h4><p>&emsp;&emsp;在这里我们要建立一个包含两个卷积层的卷积神经网络，并在训练时使用dropout。网络的前向传播过程为：输入数据经过reshape变形为二维图形数据，输入一个filter为5×5，步长为1，padding为same的卷积层，经过relu激活函数后输入一个步长为2，padding为same的max池化层。再经过一个相同的卷积层+relu+池化层组合后，将输出变形为一个列向量，输入一个全连接层。该全连接层输出为一个项数为1024的向量。之后经过dropout后再将其输入至另一个1024×10的全连接层，最终得到一个1×10的向量，即输出向量。整个卷积神经网络结构如下：<br><img src="/images/Tensorflow_02_mnist_cnn.png" alt="mnist_cnn"></p>
<h4 id="定义张量-1"><a href="#定义张量-1" class="headerlink" title="定义张量"></a>定义张量</h4><p>&emsp;&emsp;卷积神经网络由于有多个层，每个层都会有权重W和偏差b。在这里我们不像之前那样将它们全部初始化为0，而是初始化为一些很小的随机数,因为在深度网络中全部初始化为0会造成梯度上的一些问题。为了方便起见，我们将W及b的定义与初始化放入函数中，这样可以使代码更加美观直接：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义W初始化函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span>(<span class="params">shape</span>):</span></span><br><span class="line">    initial = tf.truncated_normal(shape, stddev = <span class="number">0.1</span>)</span><br><span class="line">    <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义b初始化函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span>(<span class="params">shape</span>):</span></span><br><span class="line">    initial = tf.constant(<span class="number">0.1</span>, shape = shape)</span><br><span class="line">    <span class="keyword">return</span> tf.Variable(initial)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;初始化权重时，我们使用了tf.truncated_normal(shape, mean, stddev)函数（<a target="_blank" rel="noopener" href="https://www.tensorflow.org/versions/master/api_docs/python/tf/truncated_normal">官方文档</a>）,其中shape代表生成张量的维度，mean代表均值，stddev代表标准差。与tf.random_normal()不同，它是从截断的正太分布中输出维度为shape的随机数，且该正太分布服从均值为mean，标准差为stddev。截断的意思指生成的随机数不能离均值太远，只能在[μ-2σ，μ+2σ]之间取值。若生成的随机数超过了这个区间，则函数会自动舍弃并重新生成，这保证了参数的初始值不会太大。因此它经常被用来初始化训练参数。参数初始化后使用tf.Variable()定义张量。<br>&emsp;&emsp;初始化偏差时，我们将它们统一初始化为0.1，再定义Variable张量即可。<br>&emsp;&emsp;定义完函数后我们将使用它们对各个模型参数进行定义和初始化，同时定义x与y_。每个卷积层和全连接层都有一个W和一个b，而池化层没有参数，定义时要注意它们的维度计算。除此之外我们还需要定义dropout的概率参数，因为在训练模型和评估模型时它们的值是不同的。代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义张量</span></span><br><span class="line">x = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">784</span>])</span><br><span class="line">y_ = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化W,b</span></span><br><span class="line">W_conv1 = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">32</span>]) <span class="comment">#第一个卷积层权重</span></span><br><span class="line">b_conv1 = bias_variable([<span class="number">32</span>]) <span class="comment">#第一个卷积层偏差</span></span><br><span class="line">W_conv2 = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">32</span>, <span class="number">64</span>]) <span class="comment">#第二个卷积层权重</span></span><br><span class="line">b_conv2 = bias_variable([<span class="number">64</span>]) <span class="comment">#第二个卷积层偏差</span></span><br><span class="line">W_fc1 = weight_variable([<span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>, <span class="number">1024</span>]) <span class="comment">#第一个全连接层权重</span></span><br><span class="line">b_fc1 = bias_variable([<span class="number">1024</span>]) <span class="comment">#第一个全连接层偏差</span></span><br><span class="line">W_fc2 = weight_variable([<span class="number">1024</span>, <span class="number">10</span>]) <span class="comment">#第二个全连接层权重</span></span><br><span class="line">b_fc2 = bias_variable([<span class="number">10</span>]) <span class="comment">#第二个全连接层偏差</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义dropout参数</span></span><br><span class="line">keep_prob = tf.placeholder(tf.float32)</span><br></pre></td></tr></table></figure>
<h4 id="构建computational-graph-1"><a href="#构建computational-graph-1" class="headerlink" title="构建computational graph"></a>构建computational graph</h4><p>&emsp;&emsp;根据之前规划的网络结构来构建computational graph。卷积神经网络的各个层都可以使用tf.nn模块中定义的函数实现。这里我们使用的函数如下：<br>&emsp;&emsp;**tf.nn.conv2d(input, filter, strides, padding)**（<a target="_blank" rel="noopener" href="https://www.tensorflow.org/versions/master/api_docs/python/tf/nn/conv2d">官方文档</a>）：使用filter对输入input进行卷积，其卷积的步长为strides，padding为padding。<br>&emsp;&emsp;**tf.nn.relu(feature)**（<a target="_blank" rel="noopener" href="https://www.tensorflow.org/versions/master/api_docs/python/tf/nn/relu">官方文档</a>）：对输入feature进行relu运算。<br>&emsp;&emsp;**tf.nn.max_pool(value, ksize, strides, padding)**（<a target="_blank" rel="noopener" href="https://www.tensorflow.org/versions/master/api_docs/python/tf/nn/max_pool">官方文档</a>）：使用ksize设定的窗对输入value进行池化运算，其步长为strides，padding为padding。<br>&emsp;&emsp;全连接层没有专门的函数，直接使用Tensorflow的矩阵运算就可以了。构建网络的代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#构建computational graph</span></span><br><span class="line">x_image = tf.reshape(x, [<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>])</span><br><span class="line">Z1 = tf.nn.conv2d(x_image, W_conv1, strides = [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding = <span class="string">&#x27;SAME&#x27;</span>) + b_conv1</span><br><span class="line">A1 = tf.nn.relu(Z1)</span><br><span class="line">P1 = tf.nn.max_pool(A1, ksize = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding = <span class="string">&#x27;SAME&#x27;</span>)</span><br><span class="line">Z2 = tf.nn.conv2d(P1, W_conv2, strides = [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding = <span class="string">&#x27;SAME&#x27;</span>) + b_conv2</span><br><span class="line">A2 = tf.nn.relu(Z2)</span><br><span class="line">P2 = tf.nn.max_pool(A2, ksize = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding = <span class="string">&#x27;SAME&#x27;</span>)</span><br><span class="line">P2_flat = tf.reshape(P2, [<span class="number">-1</span>, <span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>])</span><br><span class="line">Z3 = tf.matmul(P2_flat, W_fc1) + b_fc1</span><br><span class="line">A3 = tf.nn.relu(Z3)</span><br><span class="line">D1 = tf.nn.dropout(A3, keep_prob)</span><br><span class="line">y = tf.matmul(D1, W_fc2) + b_fc2</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;最后定义代价函数，其方法与softmax回归模型一致：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义代价函数</span></span><br><span class="line">cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y_, logits = y))</span><br></pre></td></tr></table></figure>
<h4 id="设置训练目标与评价参数"><a href="#设置训练目标与评价参数" class="headerlink" title="设置训练目标与评价参数"></a>设置训练目标与评价参数</h4><p>&emsp;&emsp;在这里我们使用Adam的优化方法来降低代价函数的损失值。在这里要注意的是，程序中对Variable的初始化要在Adam定义之后，不然会报错，这可能是因为Adam的函数中本身也定义了一些Variable需要初始化。因此在写Tensorflow时我都习惯将初始化的代码放在训练之前。代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#设置训练目标</span></span><br><span class="line">train_step = tf.train.AdamOptimizer(<span class="number">1e-4</span>).minimize(cross_entropy)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;若我们希望训练过程中输出模型的精确度，则需要在训练之前设置评估参数。其设置方法与softmax回归模型一致：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#设置评估参数</span></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y, <span class="number">1</span>), tf.argmax(y_, <span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br></pre></td></tr></table></figure>
<h4 id="训练参数-1"><a href="#训练参数-1" class="headerlink" title="训练参数"></a>训练参数</h4><p>&emsp;&emsp;在初始化Variable之后使用for循环对参数进行训练，其实现过程与softmax类似。由于网络参数较多，我们每次使用数据量为50的batch迭代20000次。并且每迭代1000次输出模型对训练集的精确度。其实现代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Variable初始化</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"><span class="comment">#循环训练</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20000</span>):</span><br><span class="line">    batch_xs, batch_ys = mnist.train.next_batch(<span class="number">50</span>)</span><br><span class="line">    sess.run(train_step, feed_dict = &#123;x: batch_xs, y_: batch_ys, keep_prob: <span class="number">0.5</span>&#125;)</span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">        train_accuracy = sess.run(accuracy, feed_dict = &#123;x: batch_xs, y_: batch_ys, keep_prob: <span class="number">1</span>&#125;)</span><br><span class="line">        print(<span class="string">&quot;step&quot;</span>, i, <span class="string">&quot;training accuracy:&quot;</span>,train_accuracy)</span><br></pre></td></tr></table></figure>
<h4 id="评估模型-1"><a href="#评估模型-1" class="headerlink" title="评估模型"></a>评估模型</h4><p>&emsp;&emsp;最后使用测试集对模型进行评估并输出最终精确度：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#输出</span></span><br><span class="line">test_accuracy = sess.run(accuracy, feed_dict = &#123;x: mnist.test.images, y_: mnist.test.labels, keep_prob: <span class="number">1</span>&#125;)</span><br><span class="line">print(<span class="string">&quot;test accuracy:&quot;</span>, test_accuracy)</span><br><span class="line">sess.close()</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;这样就已经大功告成啦！打开终端运行代码，整个训练过程可能要持续半小时或者更久（由你CPU或GPU水平决定）。休息下喝杯茶吧！<br>&emsp;&emsp;最终的输出为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">step <span class="number">0</span> training accuracy: <span class="number">0.04</span></span><br><span class="line">step <span class="number">1000</span> training accuracy: <span class="number">0.96</span></span><br><span class="line">step <span class="number">2000</span> training accuracy: <span class="number">1.0</span></span><br><span class="line">step <span class="number">3000</span> training accuracy: <span class="number">1.0</span></span><br><span class="line">step <span class="number">4000</span> training accuracy: <span class="number">0.98</span></span><br><span class="line">step <span class="number">5000</span> training accuracy: <span class="number">1.0</span></span><br><span class="line">step <span class="number">6000</span> training accuracy: <span class="number">1.0</span></span><br><span class="line">step <span class="number">7000</span> training accuracy: <span class="number">1.0</span></span><br><span class="line">step <span class="number">8000</span> training accuracy: <span class="number">1.0</span></span><br><span class="line">step <span class="number">9000</span> training accuracy: <span class="number">1.0</span></span><br><span class="line">step <span class="number">10000</span> training accuracy: <span class="number">1.0</span></span><br><span class="line">step <span class="number">11000</span> training accuracy: <span class="number">1.0</span></span><br><span class="line">step <span class="number">12000</span> training accuracy: <span class="number">1.0</span></span><br><span class="line">step <span class="number">13000</span> training accuracy: <span class="number">1.0</span></span><br><span class="line">step <span class="number">14000</span> training accuracy: <span class="number">1.0</span></span><br><span class="line">step <span class="number">15000</span> training accuracy: <span class="number">1.0</span></span><br><span class="line">step <span class="number">16000</span> training accuracy: <span class="number">1.0</span></span><br><span class="line">step <span class="number">17000</span> training accuracy: <span class="number">1.0</span></span><br><span class="line">step <span class="number">18000</span> training accuracy: <span class="number">1.0</span></span><br><span class="line">step <span class="number">19000</span> training accuracy: <span class="number">1.0</span></span><br><span class="line">test accuracy: <span class="number">0.9918</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;每个人得到的结果会略有不同，因为参数初始化时是随机的，但大致都在99.2%左右，比softmax回归模型提高了很多！</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ol>
<li>认识MNIST数据集</li>
<li>定义一个softmax回归模型，训练后得到最终精确度为92%</li>
<li>使用tf.nn中的函数能方便地定义一个卷积神经网络，训练后得到最终精确度为99.2%，相比softmax回归模型有了大幅的提升。</li>
</ol>

        </div>
        <footer class="article-footer">
            



    <a data-url="https://haosutopia.github.io/2018/01/Tensorflow-02/" data-id="ckflt9wo0002geto90opibdq0" class="article-share-link"><i class="fa fa-share"></i>分享到</a>
<script>
    (function ($) {
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

        </footer>
    </div>
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "author": {
            "@type": "Person",
            "name": "进击的学渣"
        },
        "headline": "Tensorflow学习（二）",
        "image": "https://haosutopia.github.io/images/Tensorflow.png",
        "keywords": "Tensorflow",
        "genre": "机器学习 深度学习",
        "datePublished": "2018-01-12",
        "dateCreated": "2018-01-12",
        "dateModified": "2018-01-24",
        "url": "https://haosutopia.github.io/2018/01/Tensorflow-02/",
        "description": "&emsp;&emsp;当我们学习一个新的编程语言时，输出的第一句话一定是“Hallo World”；当我们学习一个新的深度学习框架时，跑的第一个数据集一定是MNIST。这是Tensorflow官方教程的原话。MNIST是一个简单的计算机图像数据集，它由一系列大小为28×28的手写数字图像以及它们的标记组成（如下图所示），可以算是最简单的数据集之一啦。&emsp;&emsp;本次学习会使用两种不同",
        "wordCount": 1021
    }
</script>

</article>

    <section id="comments">
    
        
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>


    
    </section>



                        </div>
                    </section>
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    <div class="sidebar-top">
        <p>关注我 :</p>
        <ul class="social-links">
            
                
                <li>
                    <a class="social-tooltip" title="twitter" href="/" target="_blank" rel="noopener">
                        <i class="icon fa fa-twitter"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="facebook" href="https://www.facebook.com/people/%E7%8E%8B%E8%AF%9A%E7%9A%93/100004082464920" target="_blank" rel="noopener">
                        <i class="icon fa fa-facebook"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="instagram" href="https://www.instagram.com/changhao_wang0809/" target="_blank" rel="noopener">
                        <i class="icon fa fa-instagram"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="github" href="https://github.com/HaosUtopia" target="_blank" rel="noopener">
                        <i class="icon fa fa-github"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="weibo" href="/" target="_blank" rel="noopener">
                        <i class="icon fa fa-weibo"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="rss" href="/" target="_blank" rel="noopener">
                        <i class="icon fa fa-rss"></i>
                    </a>
                </li>
                
            
        </ul>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2018/01/Backstepping-01/" id="article-nav-newer" class="article-nav-link-wrap">
        <strong class="article-nav-caption">下一篇</strong>
        <p class="article-nav-title">
        
            Backstepping（反步控制）
        
        </p>
        <i class="icon fa fa-chevron-right" id="icon-chevron-right"></i>
    </a>
    
    
        <a href="/2018/01/Tensorflow-01/" id="article-nav-older" class="article-nav-link-wrap">
        <strong class="article-nav-caption">上一篇</strong>
        <p class="article-nav-title">Tensorflow学习（一）</p>
        <i class="icon fa fa-chevron-left" id="icon-chevron-left"></i>
        </a>
    
</nav>

    
    <div class="widgets-container">
        
            
                
    <div class="widget-wrap">
        <h3 class="widget-title">最新文章</h3>
        <div class="widget">
            <ul id="recent-post" class="">
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/08/Computer-Vision-01/" class="thumbnail">
    
    
        <span style="background-image:url(/images/Computer_Vision.jpg)" alt="计算机视觉（一）：图像表示与梯度" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a></p>
                            <p class="item-title"><a href="/2018/08/Computer-Vision-01/" class="title">计算机视觉（一）：图像表示与梯度</a></p>
                            <p class="item-date"><time datetime="2018-08-08T19:13:45.000Z" itemprop="datePublished">2018-08-08</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/05/Decision-Tree-01/" class="thumbnail">
    
    
        <span style="background-image:url(/images/Decision_Tree.png)" alt="决策树" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></p>
                            <p class="item-title"><a href="/2018/05/Decision-Tree-01/" class="title">决策树</a></p>
                            <p class="item-date"><time datetime="2018-05-31T20:56:03.000Z" itemprop="datePublished">2018-05-31</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/04/K-Means-01/" class="thumbnail">
    
    
        <span style="background-image:url(/images/K_Means.png)" alt="K-Means聚类算法" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></p>
                            <p class="item-title"><a href="/2018/04/K-Means-01/" class="title">K-Means聚类算法</a></p>
                            <p class="item-date"><time datetime="2018-04-15T13:27:06.000Z" itemprop="datePublished">2018-04-15</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/04/RSVP-07/" class="thumbnail">
    
    
        <span style="background-image:url(/images/RSVP.png)" alt="分布参数系统控制（七）：边界输入" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/">控制理论</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%8F%82%E6%95%B0%E7%B3%BB%E7%BB%9F%E6%8E%A7%E5%88%B6/">分布参数系统控制</a></p>
                            <p class="item-title"><a href="/2018/04/RSVP-07/" class="title">分布参数系统控制（七）：边界输入</a></p>
                            <p class="item-date"><time datetime="2018-04-12T22:39:55.000Z" itemprop="datePublished">2018-04-13</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/04/RSVP-06/" class="thumbnail">
    
    
        <span style="background-image:url(/images/RSVP.png)" alt="分布参数系统控制（六）：反馈控制" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/">控制理论</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%8F%82%E6%95%B0%E7%B3%BB%E7%BB%9F%E6%8E%A7%E5%88%B6/">分布参数系统控制</a></p>
                            <p class="item-title"><a href="/2018/04/RSVP-06/" class="title">分布参数系统控制（六）：反馈控制</a></p>
                            <p class="item-date"><time datetime="2018-04-10T22:19:02.000Z" itemprop="datePublished">2018-04-11</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">分类</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/">控制理论</a><span class="category-list-count">8</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%8F%82%E6%95%B0%E7%B3%BB%E7%BB%9F%E6%8E%A7%E5%88%B6/">分布参数系统控制</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%8E%A7%E5%88%B6/">非线性控制</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span class="category-list-count">10</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span class="category-list-count">3</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a><span class="category-list-count">1</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">归档</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">八月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">五月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">四月 2018</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">三月 2018</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">一月 2018</a><span class="archive-list-count">4</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">标签</h3>
        <div class="widget">
            <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Backstepping/" rel="tag">Backstepping</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN/" rel="tag">CNN</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Caffe/" rel="tag">Caffe</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SVM/" rel="tag">SVM</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tensorflow/" rel="tag">Tensorflow</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%88%86%E5%B8%83%E5%8F%82%E6%95%B0%E7%B3%BB%E7%BB%9F/" rel="tag">分布参数系统</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/" rel="tag">数学建模</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" rel="tag">无监督学习</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AE%97%E5%AD%90%E7%90%86%E8%AE%BA/" rel="tag">算子理论</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/" rel="tag">迁移学习</a><span class="tag-list-count">1</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-float">
        <h3 class="widget-title">标签云</h3>
        <div class="widget tagcloud">
            <a href="/tags/Backstepping/" style="font-size: 13.33px;">Backstepping</a> <a href="/tags/CNN/" style="font-size: 10px;">CNN</a> <a href="/tags/Caffe/" style="font-size: 10px;">Caffe</a> <a href="/tags/Python/" style="font-size: 10px;">Python</a> <a href="/tags/SVM/" style="font-size: 16.67px;">SVM</a> <a href="/tags/Tensorflow/" style="font-size: 13.33px;">Tensorflow</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%8F%82%E6%95%B0%E7%B3%BB%E7%BB%9F/" style="font-size: 20px;">分布参数系统</a> <a href="/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/" style="font-size: 10px;">数学建模</a> <a href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">无监督学习</a> <a href="/tags/%E7%AE%97%E5%AD%90%E7%90%86%E8%AE%BA/" style="font-size: 10px;">算子理论</a> <a href="/tags/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">迁移学习</a>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">链接</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a target="_blank" rel="noopener" href="http://hexo.io">Hexo</a>
                    </li>
                
                    <li>
                        <a target="_blank" rel="noopener" href="https://www.tensorflow.org/">TensorFlow</a>
                    </li>
                
            </ul>
        </div>
    </div>


            
        
    </div>
</aside>

                </div>
            </div>
        </div>
        <footer id="footer">
    <div class="container">
        <div class="container-inner">
            <a id="back-to-top" href="javascript:;"><i class="icon fa fa-angle-up"></i></a>
            <div class="credit">
                <h1 class="logo-wrap">
                    <a href="/" class="logo"></a>
                </h1>
                <p>&copy; 2020 进击的学渣</p>
                
            </div>
            <div class="footer-plugins">
              
    


            </div>
        </div>
    </div>
</footer>

    </div>
    
    
    <script>
    var disqus_shortname = 'jin-ji-de-xue-zha';
    
    
    var disqus_url = 'https://haosutopia.github.io/2018/01/Tensorflow-02/';
    
    (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>





    
        
<script src="/libs/lightgallery/js/lightgallery.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-pager.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-zoom.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-hash.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-share.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-video.min.js"></script>

    
    
        
<script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>

    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML.js"></script>

    

    



<!-- Custom Scripts -->

<script src="/js/main.js"></script>


</body>
</html>
