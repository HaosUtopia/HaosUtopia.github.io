<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8" />

    

    
    <title>利用爬虫搜集数据 | 理想国</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="keywords" content="Python" />
    
    <meta name="description" content="&amp;emsp;&amp;emsp;训练数据对于机器学习来说是必不可少的，因此在每个机器学习任务之前都会有一个搜集数据的过程，这个搜集过程通常来说是枯燥且费时的。不像很多公司本身就是数据的生产者，对于我们普通学习者来说，能使用的大部分数据均来自于网络。我们可以从网页上手动获取所需的数据，复制粘贴到本地，然而这是相当麻烦的。通过python我们可以模拟浏览器对网页进行抓取，并自动筛选出所需要的数据，大大提高搜集">
<meta property="og:type" content="article">
<meta property="og:title" content="利用爬虫搜集数据">
<meta property="og:url" content="https://haosutopia.github.io/2018/03/Access-Web/">
<meta property="og:site_name" content="理想国">
<meta property="og:description" content="&amp;emsp;&amp;emsp;训练数据对于机器学习来说是必不可少的，因此在每个机器学习任务之前都会有一个搜集数据的过程，这个搜集过程通常来说是枯燥且费时的。不像很多公司本身就是数据的生产者，对于我们普通学习者来说，能使用的大部分数据均来自于网络。我们可以从网页上手动获取所需的数据，复制粘贴到本地，然而这是相当麻烦的。通过python我们可以模拟浏览器对网页进行抓取，并自动筛选出所需要的数据，大大提高搜集">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://haosutopia.github.io/images/AW.jpg">
<meta property="article:published_time" content="2018-03-09T22:24:15.000Z">
<meta property="article:modified_time" content="2020-09-28T02:02:27.037Z">
<meta property="article:author" content="进击的学渣">
<meta property="article:tag" content="Python">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://haosutopia.github.io/images/AW.jpg">
    

    
        <link rel="alternate" href="/" title="理想国" type="application/atom+xml" />
    

    
        <link rel="icon" href="/css/images/favicon.png" />
    

    
<link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">

    
<link rel="stylesheet" href="/libs/titillium-web/styles.css">

    
<link rel="stylesheet" href="/libs/source-code-pro/styles.css">


    
<link rel="stylesheet" href="/css/style.css">


    
<script src="/libs/jquery/3.5.0/jquery.min.js"></script>

    
    
        
<link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">

    
    
        
<link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">

    
    
        <script type="text/javascript">
(function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-115921256-1', 'auto');
ga('send', 'pageview');

</script>

    
    
        <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?fc799e8461d37896f29cc1ea74f75070";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    
    


<meta name="generator" content="Hexo 5.2.0"></head>

<body>
    <div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                    <h1 class="logo-wrap">
                        <a href="/" class="logo"></a>
                    </h1>
                    
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/home/">主页</a>
                                </li>
                            
                                    <ul class="main-nav-list"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/">控制理论</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%8F%82%E6%95%B0%E7%B3%BB%E7%BB%9F%E6%8E%A7%E5%88%B6/">分布参数系统控制</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%8E%A7%E5%88%B6/">非线性控制</a></li></ul></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li></ul></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a></li></ul>
                                
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/about/">关于</a>
                                </li>
                            
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="想要查找什么..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>


</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>

        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    <a class="page-title-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
    </h1>
</div>

                        <div class="main-body-content">
                            <article id="post-Access-Web" class="article article-single article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        利用爬虫搜集数据
        </h1>
    

            </header>
        
        
            <div class="article-meta">
                
  <div class="article-date">
    <i class="fa fa-calendar"></i>
    <a href="/2018/03/Access-Web/" class="article-date">
       <time datetime="2018-03-09T22:24:15.000Z" itemprop="datePublished">2018-03-09</time>
    </a>
  </div>


<div class="article-date">
  <i class="fa fa-calendar-plus-o"></i>
  <a href="/2018/03/Access-Web/" class="article-date">
     <time datetime="2020-09-28T02:02:27.037Z" itemprop="dateModified">2020-09-28</time>
  </a>
</div>


                

                
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link-link" href="/tags/Python/" rel="tag">Python</a>
    </div>

                

                

            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            

            

            

            <p>&emsp;&emsp;训练数据对于机器学习来说是必不可少的，因此在每个机器学习任务之前都会有一个搜集数据的过程，这个搜集过程通常来说是枯燥且费时的。不像很多公司本身就是数据的生产者，对于我们普通学习者来说，能使用的大部分数据均来自于网络。我们可以从网页上手动获取所需的数据，复制粘贴到本地，然而这是相当麻烦的。通过python我们可以模拟浏览器对网页进行抓取，并自动筛选出所需要的数据，大大提高搜集数据的效率。本次学习材料主要是<a target="_blank" rel="noopener" href="https://www.py4e.com/">Python for Everyone课程</a>、<a target="_blank" rel="noopener" href="https://www.crummy.com/software/BeautifulSoup/">BeautifulSoup官网</a>以及一些网上的资料。</p>
<h3 id="socket接收数据"><a href="#socket接收数据" class="headerlink" title="socket接收数据"></a>socket接收数据</h3><p>&emsp;&emsp;计算机上的应用程序通常是通过套接字（socket）与外界进行联系的。socket就相当于一个端口，程序通过它向网络服务器发出请求或应答网络请求。Python拥有一个内置的socket库，在它的帮助下我们能够轻松连接网络服务器并获取服务器上的数据。在使用之前我们需要导入socket库：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> socket</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;使用socket函数为我们的程序定义一个socket：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) <span class="comment">#定义一个socket，并命名为mysock</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;第一个参数socket.AF_INET代表这个socket是用于服务器与服务器之间的网络通信；第二个参数socket.SOCK_STREAM代表它是基于TCP的流式socket通信。我们在网页抓取中使用的都是基于TCP的网络通信，因此在使用socket获取网络数据时，这些参数都是不变的。<br>&emsp;&emsp;定义完socket后，我们需要将它连接到网络上的服务器端口。通常服务器不同端口分别提供不同的服务，TCP/IP协议规定Web服务使用80号端口，因此我们使用connect将socket连接到指定服务器的80号端口。这里我们以<a target="_blank" rel="noopener" href="http://data.pr4e.org/">data.pr4e.org</a>为例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysock.connect((<span class="string">&#x27;data.pr4e.org&#x27;</span>, <span class="number">80</span>)) <span class="comment">#连接到data.pr4e.org的80号端口</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;若想获得该服务器上的某个文件（如romeo.txt），我们就需要通过socket对服务器发出请求。根据HTTP协议，请求数据时需要使用send向服务器发送一个结尾为空行的GET指令。由于python3使用Unicode来表示文字，而在网络传输中使用的是二进制格式，因此我们需要使用encode函数将Unicode编码为二进制再通过socket传递；同样在接收服务器数据后我们也需要使用decode对数据进行转换。代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cmd = <span class="string">&#x27;GET http://data.pr4e.org/romeo.txt HTTP/1.0\r\n\r\n&#x27;</span>.encode() <span class="comment">#设置GET指令并编码</span></span><br><span class="line">mysock.send(cmd) <span class="comment">#通过socket发送指令</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;发送完指令后就可以等待接收服务器的数据了。在这里我们使用一个for循环对数据进行接收，每次接收512个字节，直到接收完毕。代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">  data = mysock.recv(<span class="number">512</span>) <span class="comment">#每次接收512字节</span></span><br><span class="line">  <span class="keyword">if</span>(len(data) &lt; <span class="number">1</span>): <span class="comment">#若接收数据为空，则跳出循环</span></span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line">print(data.decode(),end=<span class="string">&#x27;&#x27;</span>) <span class="comment">#编码后打印接收到的数据</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;最后接收完毕，我们需要将socket关闭：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysock.close()</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;程序输出结果为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">HTTP&#x2F;1.1 200 OK</span><br><span class="line">Date: Sun, 14 Mar 2010 23:52:41 GMT</span><br><span class="line">Server: Apache</span><br><span class="line">Last-Modified: Tue, 29 Dec 2009 01:31:22 GMT</span><br><span class="line">ETag: &quot;143c1b33-a7-4b395bea&quot;</span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line">Content-Length: 167</span><br><span class="line">Connection: close</span><br><span class="line">Content-Type: text&#x2F;plain</span><br><span class="line"></span><br><span class="line">But soft what light through yonder window breaks</span><br><span class="line">It is the east and Juliet is the sun</span><br><span class="line">Arise fair sun and kill the envious moon</span><br><span class="line">Who is already sick and pale with grief</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;接收到的数据分为两个部分，它们使用一个空行分隔。空行前的部分是文件的头部（headers），它由网络服务器生成，用来描述文件的属性。比如最后一项<em>Content-Type: text/plain</em>表示文件是一个纯文本。空行后的部分才是文件真正的数据部分，因此在接收完数据后我们还需要对数据进行部分处理才能使用。在这里我们接收的是文本文件，而其他数据类型如图片等都是类似的，因为它们在网络中都是通过二进制传递。我们只需在接收完成后进行相应的解码就可以了。<br>&emsp;&emsp;使用socket库需要我们手动发送请求给服务器并接收，还是有些麻烦的。接下来我们将使用另一个更加方便的库来实现之前的功能。</p>
<h3 id="urllib接收数据"><a href="#urllib接收数据" class="headerlink" title="urllib接收数据"></a>urllib接收数据</h3><p>&emsp;&emsp;urllib也是python的一个内置库，利用它我们可以把接收到的数据当作一个file进行处理，非常的方便。在使用之前我们需要导入urllib库：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request, urllib.parse, urllib.error</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;在这里我们只需要一个命令便可以请求并接收所需文件数据。：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fhand = urllib.request.urlopen(<span class="string">&#x27;http://data.pr4e.org/romeo.txt&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;fhand是网络文件的句柄（handle），我们可以像file那样对fhand进行操作，比如使用for循环将文件内容逐行显示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> fhand:</span><br><span class="line">  print(line.decode().strip()) <span class="comment">#打印解码后的行</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;也可以使用read()直接将整个文件读取为一个string。这里要注意，使用read()时文件不能大过计算机的内存：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(fhand.read()) <span class="comment">#读取整个文件并打印</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;与socket不同，urllib会将接收数据的头部（headers）与内容（content）分开，因此上面程序运行输出的是不含头部的文件数据。若要获取文件的头部，我们只需对fhand使用info()即可；</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">info = fhand.info()</span><br></pre></td></tr></table></figure>
<h3 id="BeautifulSoup分析网页源码"><a href="#BeautifulSoup分析网页源码" class="headerlink" title="BeautifulSoup分析网页源码"></a>BeautifulSoup分析网页源码</h3><p>&emsp;&emsp;通常在服务器抓取数据时，我们不知道目标文件的网络地址，因此需要通过分析网页的源码来得到它们。例如我们想获取下图百度首页上的logo图片：<br><img src="/images/AW_Baidu.png" alt="百度网页"><br>&emsp;&emsp;但我们只知道百度的网址是：<a target="_blank" rel="noopener" href="https://www.baidu.com/">www.baidu.com</a>。这时候我们只能通过python抓取网页的源码，对其进行分析后才能得到该图片的网络地址。分析源码后我们得到表示该图片的img标签：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">img</span> <span class="attr">hidefocus</span>=<span class="string">&quot;true&quot;</span> <span class="attr">src</span>=<span class="string">&quot;//www.baidu.com/img/bd_logo1.png&quot;</span> <span class="attr">usemap</span>=<span class="string">&quot;#mp&quot;</span> <span class="attr">width</span>=<span class="string">&quot;270&quot;</span> <span class="attr">height</span>=<span class="string">&quot;129&quot;</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;其中<em>src</em>属性的值就是该图片的网络地址。由于网页的源码通常非常复杂，并且很多网站编写时并不是特别规范，因此使用传统方式对源码进行分析是非常困难的。幸好我们有个强大的工具——BeautifulSoup（不知道哪位老哥起的奇葩名字）。它可以将HTML的标签通过节点表示，建立一个文档树。通过这个文档树，我们可以方便地找到想要的标签并提取出其中的内容。在整个数据抓取过程中，我们利用urllib抓取网页源码，再使用BeatifulSoup对网页源码进行分析。不过在这之前我们需要对HTML的语法结构以及标签类型有一个初步的认识，具体可以参考<a target="_blank" rel="noopener" href="https://developer.mozilla.org/zh-CN/docs/Web/HTML">MDN</a>的教程。<br>&emsp;&emsp;根据<a target="_blank" rel="noopener" href="https://www.crummy.com/software/BeautifulSoup/#Download">官网</a>提示安装BeautifulSoup，安装完毕后便可以开始写程序了。我们以一个简单的网页（<a target="_blank" rel="noopener" href="http://www.dr-chuck.com/page1.htm">www.dr-chuck.com/page1.htm</a>）为例，它的HTML代码为：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">head</span>&gt;</span><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h1</span>&gt;</span>The First Page<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span></span><br><span class="line">      If you like, you can switch to the</span><br><span class="line">      <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;http://www.dr-chuck.com/page2.htm&quot;</span>&gt;</span>Second Page<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">      .</span><br><span class="line">    <span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;首先导入urllib与BeautifulSoup库：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request, urllib.parse, urllib.error</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;使用urllib读取页面源码，并储存在一个变量中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">url = <span class="string">&quot;http://www.dr-chuck.com/page1.htm&quot;</span> <span class="comment">#设置网页链接</span></span><br><span class="line">html = urllib.request.urlopen(url).read() <span class="comment">#将网页源码储存在变量html中</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;使用该变量创建一个BeautifulSoup对象：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">soup = BeautifulSoup(html, <span class="string">&#x27;html.parser&#x27;</span>) <span class="comment">#创建BeautifulSoup对象</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;其中第二个参数‘html.parser’表明BeautifulSoup使用的解析器为Python标准库中的HTML解析器，除此之外它还支持一些第三方解析器如lxml。lxml解析器速度更快且更加强大，不过需要安装之后才能使用。对于我们这种小打小闹，python标准库的解析器已经足够啦。<br>&emsp;&emsp;利用BeauifulSoup我们可以快速获得源码的标签（Tag）。比如我们需要获得源码中的a标签，则可使用如下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(soup.a)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;其输出为：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;http://www.dr-chuck.com/page2.htm&quot;</span>&gt;</span>Second Page<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;但是通过这种方式我们只能获得源码中的第一个a标签。若我们希望查找所有标签，可使用find_all函数，其完整定义为：find_all(name, attrs, recursive, text, **kwargs)。它有很多参数，但最常用的是name（标签类型）和attrs（标签属性）。我们可以通过指定标签类型或属性来筛选出满足条件的所有标签，并将它们合并为一个列表（list）。使用举例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(soup.find_all(<span class="string">&#x27;a&#x27;</span>)) <span class="comment">#检索所有a标签</span></span><br><span class="line">print(soup.find_all(href=<span class="string">&quot;http://www.dr-chuck.com/page2.htm&quot;</span>)) <span class="comment">#检索所有属性满足的标签</span></span><br><span class="line">print(soup.find_all(<span class="string">&#x27;a&#x27;</span>, href=<span class="string">&quot;http://www.dr-chuck.com/page2.htm&quot;</span>)) <span class="comment">#检索所有属性满足的a标签</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;由于网页源码中只有一个a标签，因此它们输出相同，均为：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;http://www.dr-chuck.com/page2.htm&quot;</span>&gt;</span>Second Page<span class="tag">&lt;/<span class="name">a</span>&gt;</span>]</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;由于输出的是一个列表，因此我们能够通过for循环来对列表中每一个标签进行操作。数据抓取中最常用的操作是获取标签的属性，我们可以通过以下两种方式得到：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(soup.a[<span class="string">&#x27;href&#x27;</span>])</span><br><span class="line">print(soup.a.get(<span class="string">&#x27;href&#x27;</span>))</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;它们的作用是一样的，输出得到a标签的’href’属性值：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">http:&#x2F;&#x2F;www.dr-chuck.com&#x2F;page2.htm</span><br><span class="line">http:&#x2F;&#x2F;www.dr-chuck.com&#x2F;page2.htm</span><br></pre></td></tr></table></figure>
<h3 id="爬虫抓取数据实例"><a href="#爬虫抓取数据实例" class="headerlink" title="爬虫抓取数据实例"></a>爬虫抓取数据实例</h3><p>&emsp;&emsp;在这里我们将利用之前介绍的相关知识，使用爬虫从一个<a target="_blank" rel="noopener" href="http://konachan.net/">动漫网站</a>上抓取动漫图片。在写代码之前我们需要观察网站及其源码，找到一些关键链接以及标签来方便之后的操作。网站外观大致如下：<br><img src="/images/AW_Website.png" alt="网站外观"><br>&emsp;&emsp;我们发现网站的图片分布在各个页面上，而每个页面的网址是有规律的，它可以表示为如下形式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http:&#x2F;&#x2F;konachan.net&#x2F;post?page&#x3D; + 页码数 + &amp;tags&#x3D;</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;在每个页面上我们需要点击缩略图来跳转到包含相应原图的网页上，因此我们要找到每个缩略图所指向的地址。使用火狐浏览器-选项-Web开发者-查看器，我们能够轻松得到页面任意位置所对应的网页源码：<br><img src="/images/AW_View.png" alt="查看器"><br>&emsp;&emsp;通过查看器我们发现每个缩略图对应的超链接标签（即a标签）都有一个类属性（class）为’thumb’。同样在包含原图的网页源码中，我们发现每一张原图对应的图片标签（即img标签）都有一个类属性为’image’。至此我们就获得了写代码需要的所有信息，可以开始写代码了。首先还是导入所需的库：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request, urllib.parse, urllib.error</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;我们使用一个循环来获得不同页面的网址，并通过urllib获取页面的源码。这里我们选择抓取前100页的图片：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">surl= <span class="string">&quot;http://konachan.net/post?page=&quot;</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">101</span>):</span><br><span class="line">    url = surl + str(i) + <span class="string">&quot;&amp;tags=&quot;</span> <span class="comment">#得到第i页网址</span></span><br><span class="line">    html = urllib.request.urlopen(url).read() <span class="comment">#得到第i页源码</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;创建BeautifulSoup对象，并通过find_all函数找到所有类属性为‘thumb’的超链接标签：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">soup = BeautifulSoup(html, <span class="string">&#x27;html.parser&#x27;</span>) <span class="comment">#创建BeautifulSoup对象</span></span><br><span class="line">tags = soup.find_all(<span class="string">&#x27;a&#x27;</span>, class_=<span class="string">&quot;thumb&quot;</span>) <span class="comment">#得到所有类属性为thumb的的超链接标签（由于class为python关键字，因此使用class_来表示）</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;使用for循环遍历标签列表，得到每一个标签的链接地址：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> a <span class="keyword">in</span> tags:</span><br><span class="line">  iurl = <span class="string">&#x27;http://konachan.net&#x27;</span> + a[<span class="string">&#x27;href&#x27;</span>]; <span class="comment">#得到网络地址</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;这些网络地址均为包含原图的网页。使用与之前相同的方法得到网页源码，并利用BeautifulSoup得到图片地址：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ihtml = urllib.request.urlopen(iurl).read() <span class="comment">#得到网页源码</span></span><br><span class="line">isoup = BeautifulSoup(ihtml, <span class="string">&#x27;html.parser&#x27;</span>) <span class="comment">#创建BeautifulSoup对象</span></span><br><span class="line">itag = isoup.find_all(<span class="string">&#x27;img&#x27;</span>, class_=<span class="string">&#x27;image&#x27;</span>) <span class="comment">#得到所有类属性为image的img标签</span></span><br><span class="line">iiurl = <span class="string">&#x27;http:&#x27;</span> + itag[<span class="number">0</span>][<span class="string">&#x27;src&#x27;</span>] <span class="comment">#得到图片地址</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;最后使用urllib获得图片数据，并保存至本地。由于我们不确定图片的格式，因此使用图片地址末尾的后缀来创建文件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">f = open(<span class="string">&#x27;image_name&#x27;</span> + <span class="string">&#x27;.&#x27;</span> + iiurl.split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">-1</span>], <span class="string">&#x27;wb&#x27;</span>) <span class="comment">#创建图片文件</span></span><br><span class="line">f.write(urllib.request.urlopen(iiurl).read()) <span class="comment">#写入图片数据</span></span><br><span class="line">f.close <span class="comment">#关闭图片文件</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;完整代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request, urllib.parse, urllib.error</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">k = <span class="number">1</span>;</span><br><span class="line">surl= <span class="string">&quot;http://konachan.net/post?page=&quot;</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">101</span>):</span><br><span class="line">    url = surl + str(i) + <span class="string">&quot;&amp;tags=&quot;</span></span><br><span class="line">    html = urllib.request.urlopen(url).read()</span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">&#x27;html.parser&#x27;</span>)</span><br><span class="line">    tags = soup.find_all(<span class="string">&#x27;a&#x27;</span>, class_=<span class="string">&quot;thumb&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> a <span class="keyword">in</span> tags:</span><br><span class="line">        iurl = <span class="string">&#x27;http://konachan.net&#x27;</span> + a[<span class="string">&#x27;href&#x27;</span>];</span><br><span class="line">        ihtml = urllib.request.urlopen(iurl).read()</span><br><span class="line">        isoup = BeautifulSoup(ihtml, <span class="string">&#x27;html.parser&#x27;</span>)</span><br><span class="line">        itag = isoup.find_all(<span class="string">&#x27;img&#x27;</span>, class_=<span class="string">&#x27;image&#x27;</span>)</span><br><span class="line">        iiurl = <span class="string">&#x27;http:&#x27;</span> + itag[<span class="number">0</span>][<span class="string">&#x27;src&#x27;</span>]</span><br><span class="line">        f = open(<span class="string">&#x27;images/&#x27;</span> + str(k) + <span class="string">&#x27;.&#x27;</span> + iiurl.split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">-1</span>], <span class="string">&#x27;wb&#x27;</span>)</span><br><span class="line">        f.write(urllib.request.urlopen(iiurl).read())</span><br><span class="line">        f.close</span><br><span class="line">        print(<span class="string">&#x27;image&#x27;</span> + str(k) + <span class="string">&#x27; produced&#x27;</span>)</span><br><span class="line">        k = k + <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;在这里我们用递增的变量k来命名文件，以方便之后的操作，并将它们保存在images文件夹中。至此我们便使用爬虫完成了一个简单的数据抓取任务。当然在抓取数据时还会遇到各种其他问题，比如需要登录才能获取数据，或者数据被加密了（这在视频网站很常见），之后有时间再研究吧。最终抓取的图片如下：<br><img src="/images/AW_Output.png" alt="抓取结果"></p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ol>
<li>使用socket能够连接网络服务器并进行数据请求及回应。</li>
<li>使用urllib能够更方便地实现网页抓取。</li>
<li>BeautifulSoup能够帮助我们分析网页源码并获取有用信息。</li>
</ol>

        </div>
        <footer class="article-footer">
            



    <a data-url="https://haosutopia.github.io/2018/03/Access-Web/" data-id="ckflvu1b80000qqo9fwinehc0" class="article-share-link"><i class="fa fa-share"></i>分享到</a>
<script>
    (function ($) {
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

        </footer>
    </div>
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "author": {
            "@type": "Person",
            "name": "进击的学渣"
        },
        "headline": "利用爬虫搜集数据",
        "image": "https://haosutopia.github.io/images/AW.jpg",
        "keywords": "Python",
        "genre": "机器学习",
        "datePublished": "2018-03-09",
        "dateCreated": "2018-03-09",
        "dateModified": "2020-09-28",
        "url": "https://haosutopia.github.io/2018/03/Access-Web/",
        "description": "&emsp;&emsp;训练数据对于机器学习来说是必不可少的，因此在每个机器学习任务之前都会有一个搜集数据的过程，这个搜集过程通常来说是枯燥且费时的。不像很多公司本身就是数据的生产者，对于我们普通学习者来说，能使用的大部分数据均来自于网络。我们可以从网页上手动获取所需的数据，复制粘贴到本地，然而这是相当麻烦的。通过python我们可以模拟浏览器对网页进行抓取，并自动筛选出所需要的数据，大大提高搜集",
        "wordCount": 930
    }
</script>

</article>

    <section id="comments">
    
        
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>


    
    </section>



                        </div>
                    </section>
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    <div class="sidebar-top">
        <p>关注我 :</p>
        <ul class="social-links">
            
                
                <li>
                    <a class="social-tooltip" title="twitter" href="/" target="_blank" rel="noopener">
                        <i class="icon fa fa-twitter"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="facebook" href="https://www.facebook.com/people/%E7%8E%8B%E8%AF%9A%E7%9A%93/100004082464920" target="_blank" rel="noopener">
                        <i class="icon fa fa-facebook"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="instagram" href="https://www.instagram.com/changhao_wang0809/" target="_blank" rel="noopener">
                        <i class="icon fa fa-instagram"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="github" href="https://github.com/HaosUtopia" target="_blank" rel="noopener">
                        <i class="icon fa fa-github"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="weibo" href="/" target="_blank" rel="noopener">
                        <i class="icon fa fa-weibo"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="rss" href="/" target="_blank" rel="noopener">
                        <i class="icon fa fa-rss"></i>
                    </a>
                </li>
                
            
        </ul>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2018/03/SVM-01/" id="article-nav-newer" class="article-nav-link-wrap">
        <strong class="article-nav-caption">下一篇</strong>
        <p class="article-nav-title">
        
            支持向量机（一）
        
        </p>
        <i class="icon fa fa-chevron-right" id="icon-chevron-right"></i>
    </a>
    
    
        <a href="/2018/03/RSVP-03/" id="article-nav-older" class="article-nav-link-wrap">
        <strong class="article-nav-caption">上一篇</strong>
        <p class="article-nav-title">分布参数系统控制（三）：求解模型</p>
        <i class="icon fa fa-chevron-left" id="icon-chevron-left"></i>
        </a>
    
</nav>

    
    <div class="widgets-container">
        
            
                
    <div class="widget-wrap">
        <h3 class="widget-title">最新文章</h3>
        <div class="widget">
            <ul id="recent-post" class="">
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/08/Computer-Vision-01/" class="thumbnail">
    
    
        <span style="background-image:url(/images/Computer_Vision.jpg)" alt="计算机视觉（一）：图像表示与梯度" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a></p>
                            <p class="item-title"><a href="/2018/08/Computer-Vision-01/" class="title">计算机视觉（一）：图像表示与梯度</a></p>
                            <p class="item-date"><time datetime="2018-08-08T19:13:45.000Z" itemprop="datePublished">2018-08-08</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/05/Decision-Tree-01/" class="thumbnail">
    
    
        <span style="background-image:url(/images/Decision_Tree.png)" alt="决策树" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></p>
                            <p class="item-title"><a href="/2018/05/Decision-Tree-01/" class="title">决策树</a></p>
                            <p class="item-date"><time datetime="2018-05-31T20:56:03.000Z" itemprop="datePublished">2018-05-31</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/04/K-Means-01/" class="thumbnail">
    
    
        <span style="background-image:url(/images/K_Means.png)" alt="K-Means聚类算法" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></p>
                            <p class="item-title"><a href="/2018/04/K-Means-01/" class="title">K-Means聚类算法</a></p>
                            <p class="item-date"><time datetime="2018-04-15T13:27:06.000Z" itemprop="datePublished">2018-04-15</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/04/RSVP-07/" class="thumbnail">
    
    
        <span style="background-image:url(/images/RSVP.png)" alt="分布参数系统控制（七）：边界输入" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/">控制理论</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%8F%82%E6%95%B0%E7%B3%BB%E7%BB%9F%E6%8E%A7%E5%88%B6/">分布参数系统控制</a></p>
                            <p class="item-title"><a href="/2018/04/RSVP-07/" class="title">分布参数系统控制（七）：边界输入</a></p>
                            <p class="item-date"><time datetime="2018-04-12T22:39:55.000Z" itemprop="datePublished">2018-04-13</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/04/RSVP-06/" class="thumbnail">
    
    
        <span style="background-image:url(/images/RSVP.png)" alt="分布参数系统控制（六）：反馈控制" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/">控制理论</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%8F%82%E6%95%B0%E7%B3%BB%E7%BB%9F%E6%8E%A7%E5%88%B6/">分布参数系统控制</a></p>
                            <p class="item-title"><a href="/2018/04/RSVP-06/" class="title">分布参数系统控制（六）：反馈控制</a></p>
                            <p class="item-date"><time datetime="2018-04-10T22:19:02.000Z" itemprop="datePublished">2018-04-11</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">分类</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/">控制理论</a><span class="category-list-count">8</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%8F%82%E6%95%B0%E7%B3%BB%E7%BB%9F%E6%8E%A7%E5%88%B6/">分布参数系统控制</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%8E%A7%E5%88%B6/">非线性控制</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span class="category-list-count">10</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span class="category-list-count">3</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a><span class="category-list-count">1</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">归档</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">八月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">五月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">四月 2018</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">三月 2018</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">一月 2018</a><span class="archive-list-count">4</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">标签</h3>
        <div class="widget">
            <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Backstepping/" rel="tag">Backstepping</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN/" rel="tag">CNN</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Caffe/" rel="tag">Caffe</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SVM/" rel="tag">SVM</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tensorflow/" rel="tag">Tensorflow</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%88%86%E5%B8%83%E5%8F%82%E6%95%B0%E7%B3%BB%E7%BB%9F/" rel="tag">分布参数系统</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/" rel="tag">数学建模</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" rel="tag">无监督学习</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AE%97%E5%AD%90%E7%90%86%E8%AE%BA/" rel="tag">算子理论</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/" rel="tag">迁移学习</a><span class="tag-list-count">1</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-float">
        <h3 class="widget-title">标签云</h3>
        <div class="widget tagcloud">
            <a href="/tags/Backstepping/" style="font-size: 13.33px;">Backstepping</a> <a href="/tags/CNN/" style="font-size: 10px;">CNN</a> <a href="/tags/Caffe/" style="font-size: 10px;">Caffe</a> <a href="/tags/Python/" style="font-size: 10px;">Python</a> <a href="/tags/SVM/" style="font-size: 16.67px;">SVM</a> <a href="/tags/Tensorflow/" style="font-size: 13.33px;">Tensorflow</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%8F%82%E6%95%B0%E7%B3%BB%E7%BB%9F/" style="font-size: 20px;">分布参数系统</a> <a href="/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/" style="font-size: 10px;">数学建模</a> <a href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">无监督学习</a> <a href="/tags/%E7%AE%97%E5%AD%90%E7%90%86%E8%AE%BA/" style="font-size: 10px;">算子理论</a> <a href="/tags/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">迁移学习</a>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">链接</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a target="_blank" rel="noopener" href="http://hexo.io">Hexo</a>
                    </li>
                
                    <li>
                        <a target="_blank" rel="noopener" href="https://www.tensorflow.org/">TensorFlow</a>
                    </li>
                
            </ul>
        </div>
    </div>


            
        
    </div>
</aside>

                </div>
            </div>
        </div>
        <footer id="footer">
    <div class="container">
        <div class="container-inner">
            <a id="back-to-top" href="javascript:;"><i class="icon fa fa-angle-up"></i></a>
            <div class="credit">
                <h1 class="logo-wrap">
                    <a href="/" class="logo"></a>
                </h1>
                <p>&copy; 2020 进击的学渣</p>
                
            </div>
            <div class="footer-plugins">
              
    


            </div>
        </div>
    </div>
</footer>

    </div>
    
    
    <script>
    var disqus_shortname = 'jin-ji-de-xue-zha';
    
    
    var disqus_url = 'https://haosutopia.github.io/2018/03/Access-Web/';
    
    (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>





    
        
<script src="/libs/lightgallery/js/lightgallery.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-pager.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-zoom.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-hash.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-share.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-video.min.js"></script>

    
    
        
<script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>

    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML.js"></script>

    

    



<!-- Custom Scripts -->

<script src="/js/main.js"></script>


</body>
</html>
